#  Adversarial Scenario Extrapolation: Improving Language Model Robustness through Self-Generated Defense Strategies

## Dataset Links:
JailbreakBench: https://jailbreakbench.github.io/

TruthfulQA: https://github.com/sylinrl/TruthfulQA

AdvGLUE: https://adversarialglue.github.io/

RealToxicityPrompt: https://huggingface.co/datasets/allenai/real-toxicity-prompts
